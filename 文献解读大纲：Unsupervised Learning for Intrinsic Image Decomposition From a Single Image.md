# 文献解读大纲：Unsupervised Learning for Intrinsic Image Decomposition From a Single Image

```
【题目】：Unsupervised Learning for Intrinsic Image Decomposition From a Single Image
【DOI】：10.1109/cvpr42600.2020.00331
【会议】：2020-CVPR
【作者】：Yunfei Liu（北京航空航天大学）, Yu Li（腾讯）, Shaodi You（阿姆斯特丹大学）, Feng Lu（鹏程实验室）
【Paper】: https://arxiv.org/abs/1911.09930
【Project】: https://liuyunfei.net/publication/cvpr2020_usi3d/external_pages/index.html
【Code】: https://github.com/DreamtaleCore/USI3D
【video】：https://www.youtube.com/watch?v=qGszWVyDF9c
 部分思路参考来自：https://blog.csdn.net/qq_39751352/article/details/126426935
```

## 1. 引言

 ### **背景介绍**

- 提出了第一个基于物理的单图像`无监督`学习用于本征图像分解网络$USI^3D$
- 图像外观影响因素：自然图像的外观受到多种因素的影响，例如光照、物体形状、材质等。
- 本征图像分解的定义：分解自然图像为反射率（与材质相关的光照不变信息）和阴影（随光照变化的信息）。是指将一幅图像分解成两个部分——反射图和照射图（或称本色图和高光图），这两幅分解得到图像就是原图像的本征图像。
- 应用场景：本征图像分解在高层次视觉任务（如纹理编辑、脸部外观调整等）中的重要性。

 ### 主要原理

$$
I = R(I) ⊙ S(I)
$$

通常用于描述图像的分解过程，其中：I表示输入图像。R(I)  表示图像的反射成分（Reflectance），即物体表面的颜色和纹理信息。S(I)表示图像的阴影成分（Shading），即由于光照和形状变化而造成的亮度变化。⊙表示逐元素相乘（Hadamard product），即在对应像素位置上相乘。

  ####  **光照模型**

本征图像分解考虑了光照对图像的影响。它通过反射率和阴影的分离，模拟了光源如何照射到物体表面，从而产生不同的亮度和颜色。

 ###  **反射与阴影的物理基础**

- **反射率（Reflectance）**：反射成分捕捉了物体的固有颜色和纹理特征。它不受光照变化的影响，主要反映物体表面的属性。

- **阴影（Shading）**：：阴影成分则与光照条件和物体形状相关，表示光源对图像亮度的影响。它包含了由于光照变化导致的亮度变化信息。

- **整体图像（Image）**：整体图像 I是由反射成分和阴影成分结合而成的。通过逐元素相乘，可以将反射和阴影信息结合，形成最终可见的图像。应用这种分解方法在图像分析、计算机视觉和图像重建等领域非常有用。通过分离反射和阴影成分，

 ####  先验知识（Prior Knowledge）

- **定义**：先验知识是指在进行某项任务之前，已经存在的关于数据或问题的知识。这些知识可以是关于数据分布、特征、结构等的信息。
- **应用**：在图像分解中，先验知识可以用于约束反射率（物体表面的颜色和纹理）和照度（光照条件），从而提高分解的准确性。

 #### 约束反射率和照度

- **反射率**：指物体表面对光的反射能力，通常与物体的材质和颜色有关。
- **照度**：指光源的强度和方向，影响图像中的亮度和阴影。
- 约束：通过引入先验知识，可以设定一些条件或限制，例如：
  - 反射率应该是正值且平滑变化。
  - 照度应该遵循某种物理规律。

  #### **物理一致性**

本征图像分解算法通常会引入物理一致性约束，确保反射率和阴影成分符合物理规律。这种约束使得分解结果在物理上合理，增强了模型的可信度。

通过将图像分解为反射和阴影成分，可以更好地理解和分析视觉现象，例如如何在不同光照条件下识别物体。

在计算机视觉中，基于物理的模型可以提高算法的鲁棒性和准确性。这些模型能够更好地处理复杂场景中的光照变化，适用于物体识别、图像修复等任务。

因此，本征图像分解被称为基于物理的，因为它利用物理原理来描述和分解图像中的光照和反射现象，使得处理结果更符合实际的物理世界。

 - ### **研究动机**
   
     - **现有方法的局限性**：
       
       - **传统方法**：如Retinex算法，受限于小数据集，复杂场景中的表现有限。
       
       Retinex算法：该算法假定大的图像梯度与反射率的变化相对应，而较小的梯度与阴影相对应。
       
       <img src="https://raw.githubusercontent.com/xuepengze/Thesis-notes/main/images/image-20241029172943723.png" style="zoom:50%;" />
       
       - **监督学习方法：**引入了各种先验来约束反射率和照度，本征图像分解是基于物理的，并不适用于高级视觉任务。同时现有的数据集要么是由一小部分人工绘制的物体、合成物体或场景或人工注释创建的。虽然效果好，但需要大量标注数据；同时数据集要么太小，要么离自然图像太远，有较大的泛化误差（换一组数据就不行了），限制了监督学习的性能。现有数据集（如MIT Intrinsic）数据少，难以获取真实反射率和阴影。
       
         <img src="https://raw.githubusercontent.com/xuepengze/Thesis-notes/main/images/image-20241029173431007.png" style="zoom:55%;" />
       
       - **半监督学习方法**：Janner等人提出了一种自监督的本征图像分解法，该方法利用少量有标记的数据和其他信息（如物体形状和光照），并将其应用于无标记数据。InverseRenderNet则使用相关图像作为输入，并通过多视角立体图像提供监督信号。
       
       - **无监督学习方法**：目前大多数无监督本征图像分解方法集中在固定场景和不同光照条件下进行训练，然后用单一输入测试模型。然而，训练用的真实图像往往局限于特定场景。因此，我们提出了一种新的无监督方法，不依赖固定结构的图像序列进行训练，专注于图像到图像的转换。该方法旨在学习两个图像域之间的映射。现有方法如$Pix_2$使用条件GAN，CycleGAN和UNIT则通过循环一致性进行训练。最近的MUNIT和DRIT假设部分共享潜空间，实现多模态转换。然而，无监督图像到图像翻译与本征图像分解之间仍存在显著差距：1）前者依赖统计特征，而后者基于物理原理；2）图像到图像的方法翻译结果多样化，而本征图像则是明确的。因此，图像到图像的转换方法无法直接应用于本征图像分解。
       
     - **无监督方法的潜力**：利用未标注数据，以学习不同领域的分布，可以更好地泛化至多样化的真实场景。

## 2. 解决方案
自然图像、反射系数和明暗处理都共享相同的内容，这些内容反映了场景中目标对象的性质。自然图像中估计反射率和照度是传递图像风格而保留图像内容。为每个集合收集三个未标记且不相关的样本。然后，应用自动编码器和生成对抗性网络。

 #### 核心思想

  1. **反射率和照度的估计**：

   - 我们将估计自然图像的反射率（物体表面的颜色和纹理）和照度（光照条件）看作是一种图像风格的转移，同时保持图像的内容不变。

  2. **无监督学习方法**：
   - 基于上述思想，我们实际上可以使用无监督学习方法来学习自然图像的风格、反射率和阴影，通过收集三组未标记且不相关的样本来学习自然图像的风格、反射率和照度。

  3. **使用自编码器和生成对抗网络**：

   - 应用自编码器（auto-encoder）和生成对抗网络（GAN）实现了在缺少标签数据情况下对图像反射率和阴影的精确分解。

 ### 自编码器

  #### 数据降维

   - **降维**：自编码器可以将高维数据映射到低维空间，从而减少数据的复杂性。这在处理高维数据（如图像、文本等）时非常有用。
   - **示例**：在图像处理中，自编码器可以将高分辨率图像压缩为较低分辨率的表示，保留重要特征。

  #### 特征学习

   - **自动特征提取**：自编码器通过学习输入数据的编码，可以自动提取出重要的特征，而无需手动选择特征。
   - **示例**：在图像分类中，自编码器可以学习到图像的边缘、纹理等重要特征，这些特征可以用于后续的分类任务。

  #### 数据重构

   - **重构能力**：自编码器的一个主要功能是能够重构输入数据。通过学习输入数据的表示，自编码器可以尝试生成与输入相似的输出。
   - **示例**：在去噪声应用中，自编码器可以学习到干净图像的特征，并用来重构被噪声污染的图像。

  ###  数据生成

   - **生成模型**：某些类型的自编码器（如变分自编码器，Variational Autoencoder）可以用于生成新数据。它们通过学习数据的潜在分布，能够生成与训练数据相似的新样本。
   - **示例**：在图像生成中，变分自编码器可以生成新的图像，具有与训练集中相似的风格和特征。

  #### 方法的独特性

- 与传统方法的区别：
  - 与传统的无监督风格转移方法不同，后者通常是在一个领域到另一个领域的转移，我们的方法则是从一个领域转移到两个具有明确物理意义的领域（反射率和照度）。

  #### 域（Domain）
  
  - **定义**：在这里，“域”可以理解为图像的特定类型或风格。例如，一个域可以是“自然图像”，而另一个域可以是“卡通风格图像”。
  - **例子**：如果将自然风景图像转换为油画风格，那么“自然图像”是源域，而“油画风格”是目标域。
  
  ####  无监督风格转换（Unsupervised Style Transfer）
  
  - **定义**：无监督风格转换是一种技术，用于在没有明确标记或配对样本的情况下，将一种图像的风格应用到另一种图像上。
  - 特点：
    - **无需配对数据**：与有监督学习不同，无监督风格转换不需要源图像和目标图像之间的直接对应关系。
    - **学习风格**：通过分析大量未标记的图像数据，模型学习到不同图像的风格特征，然后将这些特征应用于其他图像。
  
  #### 从一个域到另一个域的转换
  
  - **过程**：在风格转换过程中，模型会提取源域中的风格特征，并将其应用于目标域中的内容图像。这种转换可以是从一种艺术风格到另一种艺术风格，或从现实图像到抽象图像等。
  - **示例**：假设我们有一组自然风景图像（源域），我们希望将其转换为印象派风格（目标域）。模型会学习如何将自然图像的内容与印象派的风格结合起来，生成新的图像。
  
  #### 物理约束

为了提高方法的有效性，我们明确引入了三种物理约束：

1. **物理一致性约束**：
   
   - 确保反射率和照度之间的关系符合物理规律。
2. **领域不变内容约束**：
   
   - 确保自然图像及其分解层（反射率和照度）共享相同的对象、布局和几何形状。
3. **物理独立约束**：
   
   - 反射率与光照无关，而照度则与光照相关。这意味着反射率在不同光照条件下保持不变，而照度则会随光照变化而变化。
   
  #### 总结

综上所述，该方法通过无监督学习和物理约束，将自然图像的反射率和照度进行有效估计，同时保持图像的内容。这种方法在风格转移中引入了更深层次的物理意义，使得结果更具一致性和准确性。

## 3. 怎么做
 ### **无监督单输入本征图像分解**

无监督本征图像分解 `USI³D`定义了无监督单图像本征分解问题。我们假设收集到无标签且无关的样本，通过这些样本学习各自的外观风格。具体来说，我们通过无标签的反射图像集、阴影图像集、自然图像集、学习反射风格的边际分布`p(Rj)`、阴影风格的边际分布`p(Sk)`、自然图像风格的边际分布`p(Li)`。然后，我们的目标是从这些边际分布推断出自然图像Li的反射`R(Li)`和阴影`S(Li)`。为使任务可行，我们提出了三个假设：

- **领域不变内容**：图像、反射率和阴影共享相同的内容（即相同的物体布局和几何结构）

- **反射率和阴影的独立性**：反射率与光照无关，阴影随光照变化；这两者是互相独立的。

- **编码器的可逆性**：内容可以在域之间转换，编码为潜在特征，再重建回原图。

  #### **网络结构：**

  <img src="https://raw.githubusercontent.com/xuepengze/Thesis-notes/main/images/image-20241031103854759.png" style="zoom:50%;" />

 ### **1.领域不变：**

<img src="https://raw.githubusercontent.com/xuepengze/Thesis-notes/main/images/image-20241031103734536.png" style="zoom:20%;" />

  

  这张图展示了无监督内在图像分解方法中的**内容保持转换过程**，用于将自然图像域的图像转换为反射和阴影域的图像。

   #### 图中元素解释：

   1. **域（Domain）**
  
      - I表示自然图像域，即输入的原始图像。
      - R 表示反射域，即与光照无关的物体固有颜色和材质信息。
      - S表示阴影域，即与光照相关的阴影或光照变化信息。

   2. **共享内容空间 C**
  
      - **共享内容空间 C** 是一个域不变的潜在空间，用于编码所有域共享的内容信息（如物体形状、几何结构等），保持图像的内容一致性。
      - 自然图像 I、反射成分 R 和阴影成分 S 都能够通过各自的编码器映射到这个共享的内容空间。
  
   3. **域特定先验空间 $Z_R$ 和 $Z_S$**
  
      - **反射先验空间 $Z_R$**：用于编码与反射成分相关的特征（如表面纹理、颜色等）。
      - **阴影先验空间 $Z_S$**：用于编码与阴影成分相关的特征（如光照强度、方向等）。
      - 每个域都有各自的编码器，将域特定的外观特征编码到对应的先验空间中。

   4. **编码器和生成器之间的转换**
  
      - **编码器**（实线箭头）将图像从各个域映射到内容空间 C和对应的先验空间（$Z_R$或 $Z_S$）。
      - **生成器**（虚线箭头）则将编码后的内容和先验信息转化为目标域的图像，即反射图像和阴影图像。

   #### 转换过程概述：

  - 自然图像 I中的内容信息通过编码器提取后，传递到共享的内容空间 C，这样可以保证所有转换后的图像具有相同的基本结构。
  - 自然图像的外观特征则分别编码到反射先验$Z_R$和阴影先验 $Z_S$ 中，形成与反射和阴影域对应的风格。
  - 最终，生成器会根据内容编码 C 和先验编码（$Z_R$或 $Z_S$）生成与目标域（反射或阴影）一致的图像。

   #### 总结

图中的转换过程展示了无监督内在图像分解框架如何通过共享内容编码和域特定的先验编码来将自然图像分解为反射和阴影成分。这种设计确保了生成的反射和阴影图像在内容上与原图一致，同时保持域特定的风格，从而去除光照干扰。

<img src="https://raw.githubusercontent.com/xuepengze/Thesis-notes/main/images/image-20241031103922851.png" style="zoom:50%;" />

   1. 首先，使用编码器 $E_I^C$ 来提取输入图像 $I_i$ 的内容码 $C$。
   2. 然后，使用 $C$ 分别通过生成器 $G_R$ 和 $G_S$ 生成分解层 $R(I_i)$ 和 $S(I_i)$。
   3. 最后，使用 $E_R^C$ 提取 $R(I_i)$ 的内容代码 $C_{R(I_i)}$，$E_S^C$ 提取 $S(I_i)$ 的内容代码 $C_{S(I_i)}$。

   应用内容一致性损失来使内容编码器 $E_I^C$、$E_R^C$ 和 $E_S^C$ 正常工作。具体来说，使用内容一致性损失 $L^{cnt}$ 来约束输入图像 $I_i$ 及其预测 $R(I_i)$ 和 $S(I_i)$ 之间的内容代码。

   #### **内容一致性损失：**

$$
   \mathcal{L}^{cnt} = \left| C_{R(I_i)} - C \right|_1 + \left| C_{S(I_i)} - C \right|_1
$$

   $|·|_1$ 是L1的泛数。

   用于约束输入图像的内容编码 C与其生成的两个分解层内容编码之间的一致性。这一损失项的具体含义如下：

   - **C**：是输入图像$ I_i $的内容编码，提取自编码器$ E_I^C$。
   - **$C_{R(I_i)}$**：是通过生成器 $G_R$ 生成的分解层 $R(I_i)$ 的内容编码，提取自编码器 $E_R^C$。
   - **$C_{S(I_i)}$**：是通过生成器 $G_S$ 生成的分解层 $S(I_i)$的内容编码，提取自编码器 $E_S^C$。

   公式中的$ \left| \cdot \right|_1 $表示 $L_1$ 范数，也就是绝对值之和，用于度量内容编码之间的差异。

   具体解读这个损失公式可以分为以下几点：

   1. **一致性目标**：这个损失项的作用是确保生成的分解层 $R(I_i)$ 和 $S(I_i)$的内容编码与原始输入图像的内容编码 C保持一致。这种一致性可以保证分解层在内容上仍能忠实地反映输入图像。
  
   2. **损失项的计算**：内容一致性损失 $\mathcal{L}^{cnt}$ 分为两个部分：
  
      - $| C_{R(I_i)} - C |*1$：表示 $R(I_i)$ 的内容编码 $C{R(I_i)}$ 与原始内容编码 $C$ 之间的差异。
      
        $| C_{S(I_i)} - C |*1$：表示 $S(I_i)$ 的内容编码 $C{S(I_i)}$ 与原始内容编码 $C$ 之间的差异。
  
   3. **最小化损失**：通过最小化 $L^{cnt}$，模型可以确保生成的分解层 $R(I_i)$ 和 $S(I_i)$ 的内容尽量接近原始图像的内容，从而达到更好的生成效果。

   总的来说，这个内容一致性损失 $L^{cnt}$ 用于引导模型生成的内容编码保持一致，从而确保分解层内容与原始图像的一致性。

  ### 2.**反射率和阴影的独立性：**

   物理上，反射率是对照度和方向的不变性，而照度是方差。因此，为了分解反射率和照度这两个成分，假设它们的条件先验是独立的，可以分别学习。反射率的潜在先验表示为$z_R$∈$Z_R$，可以从反射率域和自然像域进行编码。照度的潜在先验表示为$z_S$∈$Z_S$，可以从照度域和自然像域进行编码。图中红色箭头表示的部分。

<img src="https://raw.githubusercontent.com/xuepengze/Thesis-notes/main/images/image-20241031104123464.png" style="zoom:44%;" />

 

   #### 匹配模块（M 模块）

<img src="https://raw.githubusercontent.com/xuepengze/Thesis-notes/main/images/image-20241031104643078.png" style="zoom:44%;" />



   在图像分解任务中，我们设计了一个 **映射模块 (M 模块)** 来帮助从输入图像 $I_i$ 中提取两个独立的先验编码：**反射编码** $z_{R(I_i)}$ 和 **阴影编码** $z_{S(I_i)}$。这个模块通过先提取图像的自然先验编码 $z_{I_i}$，然后使用一个映射函数 $f_{dcp}$ 将其分解成反射和阴影的编码。

<img src="https://raw.githubusercontent.com/xuepengze/Thesis-notes/main/images/image-20241031104734963.png" style="zoom:33%;" />

   为了确保反射编码 $z_{R(I_i)}$ 和阴影编码 $z_{S(I_i)}$ 分别符合各自的先验域 $Z_R$ 和 $Z_S$，我们使用了一种称为 **Kullback-Leibler 散度 (KLD)** 的损失函数。这种损失函数帮助模型生成符合真实反射和阴影特性的编码。

KLD 损失的基本定义：
$$
   {L}^{KL} = \mathbb{E}[\log p(\hat{z}) - \log q(z)]
$$

其中，$\hat{z}$ 是通过 M 模块提取的先验编码，$z$ 是从真实图像中提取的真实先验编码。这个损失计算的是先验编码的分布 $p$ 和真实分布 $q$ 之间的差异。

   扩展了第一个公式，表示总的 KLD 损失：

$$
   {L}^{KL}_t = \mathbb{E}[\log p(z_{R(I_i)}) - \log q(z_{R_j})] + \mathbb{E}[\log p(z_{S(I_i)}) - \log q(z_{S_k})]
$$

   这里有两个先验域：反射先验域 $Z_R$ 和阴影先验域 $Z_S$，分别对应输入图像的反射编码 $z_{R(I_i)}$ 和阴影编码 $z_{S(I_i)}$。损失计算分为两个部分：

   - 第一个部分是 $z_{R(I_i)}$ 与真实反射编码 $z_{R_j}$ 的差异。
   - 第二个部分是 $z_{S(I_i)}$ 与真实阴影编码 $z_{S_k}$ 的差异。

   通过最小化 $\mathcal{L}^{KL}_t$，模型可以将生成的编码约束在对应的真实先验域上，从而确保反射和阴影的特征符合真实数据的分布。

<img src="https://raw.githubusercontent.com/xuepengze/Thesis-notes/main/images/image-20241031104820177.png" style="zoom:44%;" />

   分两种情况：

   当真实值p(x)接近于1时，若q(x)越接近真实值1那么取对数之后的值便会接近于0使得整体值（交叉熵）越小。

   当真实值p(x)接近于0时，即使q(x)接近p(x)使得-log(q(x))接近于无穷大，而经过p(x)加权之后整体也会接近于0，但是从信息论的角度来看，低概率事件包含的信息量很小。即使模型在这些事件上的预测不准确，对信息损失的影响也相对较小。

   所以交叉熵主要针对高概率事件。

   为什么需要 KL 散度？

   虽然交叉熵包含了分布  p  和  q  之间的信息，但它本质上还包含了  p  本身的熵  H(p) ，因此无法独立表示  p  和  q  之间的差异。（我们无法判断得出的结果是否为最小值，当减去H(p)时我们可以更直观的通过散度接近0或1来判断q和p的差异，接近0时差异最小）

<img src="https://raw.githubusercontent.com/xuepengze/Thesis-notes/main/images/image-20241031104852350.png" style="zoom:44%;" />

  ### **3.**编码器的可逆性

论文中设计了三个自编码器，分别用于自然图像、反射率和阴影图层。自编码器通过将输入图像编码为隐空间表示，再解码回图像，以学习不同图层的特征。使用双向重建约束，使得重建过程可以在图像与隐空间之间来回转换，保证内容一致性。引入的图像重建损失帮助模型在编码和解码过程中还原图像，确保内容保真，从而支持在无监督条件下实现自然图像的内在分解。

   内容重建过程：
   图像 ↔ 内容隐空间 ↔ 图像
   该过程主要关注图像的全局内容信息，确保编码和解码后的图像结构和布局保持一致。
   内容隐空间中不包含光照或材质特征，仅保留图像的基础内容（形状、空间关系等）。

   风格重建过程：
   风格隐空间（反射率或阴影） ↔ 图像 ↔ 风格隐空间（反射率或阴影）
   该过程关注特定图层（如反射率或阴影）的独立特征。
   每个图层（反射率或阴影）都有各自的风格隐空间，用来捕捉与光照相关或不相关的特定风格信息，从而实现图层的分离和保留特性。

<img src="https://raw.githubusercontent.com/xuepengze/Thesis-notes/main/images/image-20241031104930650.png" style="zoom:44%;" />

   将图像样式从编码器（实线箭头）转移到生成器（虚线箭头）。

<img src="https://raw.githubusercontent.com/xuepengze/Thesis-notes/main/images/image-20241031105006671.png" style="zoom:66%;" />

图像重构损失:

$$
L^{img} = \sum_{x \in \{I_i\} \text{ or } \{R_j\} \text{ or } \{S_k\}} \left| G\left(E^c(x), E^p(x)\right) - x \right|_1
$$
   用于约束输入图像在编码和解码后能够重建回原始图像。

   先验的编码重建损失:

   给定在分解时从潜在分布中采样的先验编码，我们应该能够在解码和编码后对其进行重构。与公式 (3) 不同，公式 (3) 适用于约束两个样本的分布，图像先验编码重建 和 图像重建的约束应相同。这里我们用L1损失来表示
$$
   L^{pri} = \left| E^p_I(G_I(c_{I_i}, z_{I_i})) - z_{I_i} \right|_1 + \left| E^p_R(G_R(c_{R_j}, z_{R_j})) - z_{R_j} \right|_1 + \left| E^p_S(G_S(c_{S_k}, z_{S_k})) - z_{S_k} \right|_1
$$
   为了使分解后的固有图像在目标域中与真实图像无法区分，使用 GANs 将生成的图像的分布与目标数据分布进行匹配。对抗性损失的定义：
$$
   L^{adv}_R = \log(1 - D_R(R(I_i))) + \log D_R(R_j)$
$$

$$
   L^{adv}_S = \log(1 - D_S(S(I_i))) + \log D_S(S_k)
$$

   总对抗性损失：
$$
   L^{adv}_t = L^{adv}_R + L^{adv}_S
$$
   物理损失：
$$
   L^{phy} = \left| I_i - R(I_i) \odot S(I_i) \right|_1
$$
   总体损耗：

   通过使用 GAN 方案，联合训练编码器 E、解码器 G、映射函数 f 和鉴别器 D，以优化不同损失项的加权和。
$$
   \min_{E,G,f} \max_{D} (E, G, f, D) = L^{adv}_t + \lambda_1 L^{cnt} + \lambda_2 L^{KL} + \lambda_3 L^{img} + \lambda_4 L^{pri} + \lambda_5 L^{phy}
$$
   其中，λ1、λ2、λ3、λ4 和 λ5 是控制不同损失项重要性的权重。

  ### 生成对抗式网络

   生成对抗网络（Generative Adversarial Network，GAN）是一种深度学习模型，由两部分组成：生成器（Generator）和判别器（Discriminator）。它们通过对抗训练的方式共同优化，目的是生成与真实数据相似的假数据。（生成假数据可以解决数据稀缺、隐私问题和类别不平衡，同时增强模型的泛化能力。）以下是GAN的主要组成部分和工作原理：
   #### 组成部分
  生成器（Generator）：

  生成器的任务是从随机噪声中生成假数据。它接收随机输入（通常是高维的噪声向量），并通过神经网络生成与真实数据相似的样本。

判别器（Discriminator）：

  判别器的任务是区分输入数据是真实数据还是生成器生成的假数据。它接收真实样本和生成样本，并输出一个概率值，表示输入样本为真实数据的可能性。

   ####  工作原理

   - 对抗训练：

   - 生成器和判别器之间的训练过程是一个零和博弈。生成器试图生成越来越真实的样本，以“欺骗”判别器，而判别器则不断提高其识别能力，以区分真实样本和假样本。
     
      - 损失函数：
      
        - 生成器的目标是最大化判别器的错误率（让判别器看不出来是假数据），等价于最小化判别器的损失函数：
        
        $$
        L_D = -\left( \mathbb{E}_{x \sim p_{data}} \left[\log D(x)\right] + \mathbb{E}_{z \sim p_z} \left[\log(1 - D(G(z)))\right] \right)
        $$

   $\mathbb{E}_{x \sim p_{data}} \left[\log D(x)\right]$：

   - 这是对真实样本 x 的期望值。*D*(*x*) 是判别器对真实样本的输出概率。
   - 该项越大，说明判别器越能正确识别真实样本，从而降低损失。

   $\mathbb{E}_{z \sim p_z} \left[\log(1 - D(G(z)))\right]$：

   - 这是对生成样本 G(z)*的期望值，D(G(z))*是判别器对生成样本的输出概率。
     
   - 该项越大，说明判别器越能正确识别假样本（即输出较低的概率），同样降低损失。
     
      - 判别器的目标是最小化这个损失函数。生成器的损失函数则是：
        $$
        L_G = -\mathbb{E}_{z \sim p_z} \left[\log D(G(z))\right]
        $$
      
        $D(G(z))$越大（越接近于1）说明生成器生成的假样本越真（判别起识别不出来）则最小化生成器损失函数。
      

   **损失函数的总体目标**:
   - 判别器的损失函数$L_D$
      的目标是最小化这个值，即希望判别器能够：
   - 对真实样本 D(x)的输出尽可能接近 1（即正确判断为真实）。
   - 对生成样本 *D*(*G*(*z*)) 的输出尽可能接近 0（即正确判断为假）。
     
   ### **优化过程**：

   - 在训练过程中，判别器通过反向传播更新其参数，以最小化 $L_D$。
   - 这意味着判别器会学习到更好的特征，以区分真实样本和生成样本。

   **生成器的影响**： 
   - 生成器的目标是最大化判别器的损失，即生成更真实的样本，使得判别器对生成样本的判断变得困难，从而使得$L_D$增加。
   - 这形成了一个对抗过程：生成器与判别器相互竞争，推动彼此的性能提升。

   ### 训练过程

- 交替训练：在每个训练步骤中，首先更新判别器，然后更新生成器。通过不断交替优化，生成器和判别器逐渐提高各自的能力。

    #### 应用

- **图像生成**：GAN广泛应用于图像生成任务，如生成高质量的图像、图像修复、超分辨率等。
  
> [!NOTE]
    >
    > 在GAN的实现中，通常使用自然对数（底数为 *e*）或以 10 为底的对数，这样可以确保损失函数的行为符合预期。通常选择 a>1的对数（如自然对数），以保证损失函数的性质符合训练的需求。使用 a<1的对数在GAN中并不常见，因为这可能导致损失函数的定义变得不直观。

## 4. 实验与结果

### 1. ShapeNet 数据集实验

  定量结果：在 ShapeNet 数据集上，作者使用 MSE（均方误差）和 LMSE（局部均方误差）作为评价指标。在表格中，最终模型的 MSE 和 LMSE 分数显著优于其他方法。相比 WH18、FY18 等无监督方法，作者的模型在反射率和阴影的分解上表现更出色。
	<img src="https://raw.githubusercontent.com/xuepengze/Thesis-notes/main/images/image-20241031105304961.png" style="zoom:50%;" />
图 5 展示了 ShapeNet 数据集上的视觉对比结果。可以看到，WH18 等方法在分解时有明显的细节丢失，而作者的模型能够保留更多的细节信息，比如车辆的纹理和阴影的边界更清晰。

### 2. MPI-Sintel 基准实验

<img src="https://raw.githubusercontent.com/xuepengze/Thesis-notes/main/images/image-20241031105332250.png" style="zoom:50%;" />

定量结果：在 MPI-Sintel 基准数据集上，作者采用 MSE、LMSE 和 DSSIM（结构相似度的反向指标）作为评价标准。表 2 中显示，该方法的平均误差在所有无监督方法中最低，且接近有监督方法 MSCR。

<img src="https://raw.githubusercontent.com/xuepengze/Thesis-notes/main/images/image-20241031105449281.png" style="zoom:50%;" />

图 7 展示了 MPI-Sintel 数据集上的分解结果，与 LS18、MSCR 等方法相比，作者的模型生成的反射率和阴影图层更清晰、准确，阴影部分的光照变化被捕捉得更好。

### 3. MIT 内在数据集实验

定量结果：在 MIT 内在数据集上，作者的方法在反射率和阴影的 MSE 指标上表现最好，尤其在阴影分解上明显优于 WH18 和 Retinex 等传统方法。

<img src="https://raw.githubusercontent.com/xuepengze/Thesis-notes/main/images/image-20241031105630793.png" style="zoom:50%;" />

图 8 显示了 MIT 数据集的结果，与 MSCR 等有监督方法相比，作者的方法在反射率图层中表现了更好的材质一致性，阴影图层的光照分布也更自然。		

### 4. IIW（Intrinsic Images in the Wild）实验

定量结果：在 IIW 数据集上，作者采用 WHDR（加权人类不一致率）作为评价指标，分数越低表示结果越接近人类主观判断。表 4 显示，作者的方法 WHDR 分数达到了 18.69%，在无监督方法中表现最优，且接近有监督方法 FY18 的 14.45%。

<img src="https://raw.githubusercontent.com/xuepengze/Thesis-notes/main/images/image-20241031105727767.png" style="zoom:50%;" />


图 9 展示了 IIW 数据集的分解效果。可以看到，作者的方法生成的反射率图层平滑且一致，而阴影图层则保留了更自然的光照效果，明显优于 LS18 和 MUNIT 等无监督方法。

<img src="https://raw.githubusercontent.com/xuepengze/Thesis-notes/main/images/image-20241031105754574.png" style="zoom:50%;" />

图 6 显示，即使只使用了较少的训练样本（如 20% 的数据），该方法依然能够取得优于其他方法的分解效果。
这表明该方法在样本量较少的情况下依然具有较强的泛化能力和数据效率。

<img src="https://raw.githubusercontent.com/xuepengze/Thesis-notes/main/images/image-20241031105847674.png" style="zoom:50%;" />

### 5. 消融实验

定量结果：表 1 展示了在 ShapeNet 数据集上进行的消融实验结果。移除映射模块、内容一致性损失$L_{cnt}$和物理一致性损失$L_{phy}$后，模型的 MSE 和 LMSE 分数都有所上升，尤其是移除内容一致性损失后，细节表现明显变差。

<img src="https://raw.githubusercontent.com/xuepengze/Thesis-notes/main/images/image-20241031105935905.png" style="zoom:50%;" />

图 5 的消融实验结果列展示了去除不同模块的影响。例如，去除映射模块后，分解出的反射率和阴影在一些区域变得不准确；去除$L_{cnt}$后，阴影图层的细节丢失；去除$L_{phy}$后，虽然阴影效果看起来还可以，但在某些区域仍有错误。

<img src="https://raw.githubusercontent.com/xuepengze/Thesis-notes/main/images/image-20241031110105195.png" style="zoom:50%;" />

通过这些实验，作者证明了其无监督方法的有效性和优越性。其方法在多个数据集上表现优异，尤其在 ShapeNet 和 MPI-Sintel 数据集上获得了低误差分数，同时消融实验也展示了各个模块对模型性能的重要性，特别是内容一致性损失和物理一致性损失对细节分解的帮助很大。